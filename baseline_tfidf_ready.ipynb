{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd77bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"data/processed/train.parquet\")\n",
    "TEXT  = \"comment_text\"\n",
    "LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ff58c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:16: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.0)\n",
      "  from scipy.sparse import issparse\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "train_idx, val_idx = next(mskf.split(df[TEXT], df[LABELS]))\n",
    "X_train, X_val = df[TEXT].iloc[train_idx], df[TEXT].iloc[val_idx]\n",
    "y_train, y_val = df[LABELS].iloc[train_idx], df[LABELS].iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40ca069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    max_features=200_000,      \n",
    "    ngram_range=(1,2),        \n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf   = tfidf.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589cb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=400,\n",
    "        C=4,             \n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    ").fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db52aa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_logreg.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, os, json\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump({\"tfidf\": tfidf, \"clf\": clf},\n",
    "            \"models/tfidf_logreg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb01176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Per-label confusion matrices:\n",
      "\n",
      "toxic\n",
      "         Pred 0  Pred 1\n",
      "True 0     326      37\n",
      "True 1       2      35\n",
      "\n",
      "severe_toxic\n",
      "         Pred 0  Pred 1\n",
      "True 0     389       7\n",
      "True 1       1       3\n",
      "\n",
      "obscene\n",
      "         Pred 0  Pred 1\n",
      "True 0     361      16\n",
      "True 1       4      19\n",
      "\n",
      "threat\n",
      "         Pred 0  Pred 1\n",
      "True 0     395       3\n",
      "True 1       0       2\n",
      "\n",
      "insult\n",
      "         Pred 0  Pred 1\n",
      "True 0     361      17\n",
      "True 1       6      16\n",
      "\n",
      "identity_hate\n",
      "         Pred 0  Pred 1\n",
      "True 0     385      11\n",
      "True 1       1       3\n",
      "\n",
      "Per-label Precision, Recall, F1, Accuracy, ROC-AUC:\n",
      "               Accuracy  Precision  Recall     F1  ROC-AUC\n",
      "Label                                                     \n",
      "toxic             0.902      0.486   0.946  0.642    0.975\n",
      "severe_toxic      0.980      0.300   0.750  0.429    0.989\n",
      "obscene           0.950      0.543   0.826  0.655    0.970\n",
      "threat            0.992      0.400   1.000  0.571    1.000\n",
      "insult            0.942      0.485   0.727  0.582    0.967\n",
      "identity_hate     0.970      0.214   0.750  0.333    0.982\n",
      "\n",
      "Macro/Micro Precision, Recall, F1, ROC-AUC:\n",
      "Macro: Precision=0.728, Recall=0.904, F1=0.787, ROC-AUC=0.981\n",
      "Micro: Precision=0.956, Recall=0.956, F1=0.956\n",
      "\n",
      "Scikit-learn per-label classification report:\n",
      "               precision  recall  f1-score  support\n",
      "toxic              0.486   0.946     0.642     37.0\n",
      "severe_toxic       0.300   0.750     0.429      4.0\n",
      "obscene            0.543   0.826     0.655     23.0\n",
      "threat             0.400   1.000     0.571      2.0\n",
      "insult             0.485   0.727     0.582     22.0\n",
      "identity_hate      0.214   0.750     0.333      4.0\n",
      "\n",
      "Mean samplewise accuracy (fraction of correct labels per row): 0.956\n",
      "Subset accuracy (exact match on all labels, only full rows): 0.838\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# --- Load model ---\n",
    "model_bundle = joblib.load(\"models/tfidf_logreg.pkl\")\n",
    "tfidf = model_bundle[\"tfidf\"]\n",
    "clf = model_bundle[\"clf\"]\n",
    "\n",
    "# --- Load data ---\n",
    "LABELS = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "truth = pd.read_csv(\"test_samples_with_labels.csv\")\n",
    "\n",
    "# --- Predict ---\n",
    "X = truth[\"comment_text\"].astype(str).tolist()\n",
    "y_true = truth[LABELS].values\n",
    "\n",
    "# For samples with -1 labels (missing), we should ignore them in metrics below.\n",
    "y_pred_bin = clf.predict(tfidf.transform(X))\n",
    "y_pred_prob = clf.decision_function(tfidf.transform(X))\n",
    "\n",
    "# --- Mask for missing labels ---\n",
    "mask_matrix = (y_true != -1)\n",
    "\n",
    "# --- Evaluation ---\n",
    "def get_valid(label_idx):\n",
    "    valid = mask_matrix[:, label_idx]\n",
    "    return y_true[valid, label_idx], y_pred_bin[valid, label_idx], y_pred_prob[valid, label_idx]\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"Per-label confusion matrices:\")\n",
    "for i, label in enumerate(LABELS):\n",
    "    y_true_lbl, y_pred_lbl, _ = get_valid(i)\n",
    "    cm = confusion_matrix(y_true_lbl, y_pred_lbl)\n",
    "    print(f\"\\n{label}\\n\", pd.DataFrame(cm, index=[\"True 0\", \"True 1\"], columns=[\"Pred 0\", \"Pred 1\"]))\n",
    "\n",
    "print(\"\\nPer-label Precision, Recall, F1, Accuracy, ROC-AUC:\")\n",
    "stats = []\n",
    "for i, label in enumerate(LABELS):\n",
    "    y_true_lbl, y_pred_lbl, y_prob_lbl = get_valid(i)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true_lbl, y_pred_lbl, average='binary', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(y_true_lbl, y_pred_lbl)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true_lbl, y_prob_lbl)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    stats.append([label, acc, prec, rec, f1, auc])\n",
    "df_stats = pd.DataFrame(stats, columns=[\"Label\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC-AUC\"]).set_index(\"Label\")\n",
    "print(df_stats.round(3))\n",
    "\n",
    "print(\"\\nMacro/Micro Precision, Recall, F1, ROC-AUC:\")\n",
    "flat_true, flat_pred, flat_prob = [], [], []\n",
    "for i in range(len(LABELS)):\n",
    "    y_true_lbl, y_pred_lbl, y_prob_lbl = get_valid(i)\n",
    "    flat_true += list(y_true_lbl)\n",
    "    flat_pred += list(y_pred_lbl)\n",
    "    flat_prob += list(y_prob_lbl)\n",
    "\n",
    "prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(flat_true, flat_pred, average=\"macro\", zero_division=0)\n",
    "prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(flat_true, flat_pred, average=\"micro\", zero_division=0)\n",
    "try:\n",
    "    roc_auc_macro = roc_auc_score(flat_true, flat_prob, average=\"macro\")\n",
    "except Exception:\n",
    "    roc_auc_macro = np.nan\n",
    "\n",
    "print(f\"Macro: Precision={prec_macro:.3f}, Recall={rec_macro:.3f}, F1={f1_macro:.3f}, ROC-AUC={roc_auc_macro:.3f}\")\n",
    "print(f\"Micro: Precision={prec_micro:.3f}, Recall={rec_micro:.3f}, F1={f1_micro:.3f}\")\n",
    "\n",
    "report_dict = {}\n",
    "for i, label in enumerate(LABELS):\n",
    "    y_true_lbl, y_pred_lbl, _ = get_valid(i)\n",
    "    report = classification_report(y_true_lbl, y_pred_lbl, output_dict=True, zero_division=0)\n",
    "    report_dict[label] = report['1']\n",
    "df_report = pd.DataFrame(report_dict).T[['precision', 'recall', 'f1-score', 'support']]\n",
    "print(\"\\nScikit-learn per-label classification report:\")\n",
    "print(df_report.round(3))\n",
    "\n",
    "sample_acc = []\n",
    "for i in range(y_true.shape[0]):\n",
    "    mask = mask_matrix[i]\n",
    "    if mask.sum() == 0:\n",
    "        continue\n",
    "    sample_acc.append((y_true[i][mask] == y_pred_bin[i][mask]).mean())\n",
    "print(f\"\\nMean samplewise accuracy (fraction of correct labels per row): {np.mean(sample_acc):.3f}\")\n",
    "\n",
    "all_valid_mask = mask_matrix.all(axis=1)\n",
    "if all_valid_mask.sum():\n",
    "    subset_acc = np.mean([np.array_equal(y_true[i], y_pred_bin[i]) for i in range(len(y_true)) if all_valid_mask[i]])\n",
    "    print(f\"Subset accuracy (exact match on all labels, only full rows): {subset_acc:.3f}\")\n",
    "\n",
    "print(\"=\"*40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
