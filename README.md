# Finetuned SLMs vs. LLMs with Prompts for Toxic Comment Classification

This project explores and compares various approaches for multi-label toxic comment classification. It evaluates a classical machine learning baseline, fine-tuned Smaller Language Models (SLMs), and a Large Language Model (LLM) leveraged through advanced prompting techniques. The primary goal is to assess their effectiveness in identifying different categories of toxicity: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`.

## Key Features

*   **Classical ML Baseline**: Implementation of a TF-IDF vectorizer followed by a Logistic Regression classifier.
*   **Fine-tuned SLMs**:
    *   **BERT**: `bert-base-uncased` fine-tuned for multi-label sequence classification.
    *   **Gemma-3 4B**: `unsloth/gemma-3-4b-it` fine-tuned using Unsloth for efficiency and LoRA for parameter-efficient adaptation, trained to output comma-separated toxicity labels.
*   **LLM with Prompt Engineering**:
    *   **Gemini 2.5 Pro**: Utilized via API with carefully crafted prompts and function calling (tool usage) to classify comments into a single most prominent toxicity category or "none".
*   **Comparative Analysis**: The project provides a framework and results for comparing these diverse methodologies on a common task, albeit with slight variations in output interpretation (multi-label vs. single most severe label).

## Dataset

The project uses a dataset of comments labeled for six types of toxicity.
*   **Training Data**:
    *   `data/processed/train.parquet`: Used for the TF-IDF baseline and BERT fine-tuning.
    *   `train.csv` (expected in `/content/` for the Colab notebook): Used for Gemma-3 fine-tuning. This dataset should contain `comment_text` and the six binary label columns.
*   **Test Data**:
    *   `test_samples.csv`: Contains comment IDs and text.
    *   `test_labels.csv`: Contains comment IDs and corresponding true labels (-1 for missing labels).
    *   `test_samples_with_labels.csv`: Generated by merging `test_samples.csv` and `test_labels.csv`; used for evaluation in several notebooks.

The labels are: `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, `identity_hate`.

## Directory Structure

```
└── subhrato20-finetuned-slm-vs-llm-with-prompts/
    ├── README.md
    ├── baseline_tfidf_ready.ipynb
    ├── bert_finetune_ready.ipynb
    ├── Gemini_2_5_Pro_Cluster.ipynb
    ├── Gemma3_(4B)_finetune.ipynb
    ├── gemma_3_classification.ipynb  (Note: Content currently unavailable for detailed description)
    └── LICENSE
```
*(Data files like `train.parquet`, `test_samples.csv`, etc., are expected in appropriate subdirectories, e.g., `data/processed/` or as specified in notebooks.)*

## Models & Experiments

This repository contains Jupyter notebooks, each implementing a different approach:

*   **`baseline_tfidf_ready.ipynb`**:
    *   Implements a TF-IDF vectorizer and a OneVsRest Logistic Regression classifier.
    *   Trains the model, saves it, and evaluates it on `test_samples_with_labels.csv`.
    *   Outputs detailed multi-label classification metrics.

*   **`bert_finetune_ready.ipynb`**:
    *   Fine-tunes a `bert-base-uncased` model for multi-label toxic comment classification.
    *   Uses the Hugging Face `transformers`, `datasets`, and `Trainer` API.
    *   Saves the fine-tuned model checkpoint.
    *   Loads the checkpoint, predicts on `test_samples.csv`, and evaluates against `test_samples_with_labels.csv`.
    *   Outputs detailed multi-label classification metrics.

*   **`Gemini_2_5_Pro_Cluster.ipynb`**:
    *   Leverages the Gemini 2.5 Pro model via the OpenAI API (assuming compatibility or a similar API structure for Gemini).
    *   Uses a detailed system prompt and function calling to classify comments into a *single most severe* toxicity label or "none".
    *   Processes `test_samples.csv` asynchronously.
    *   Evaluates using a "loose cluster label accuracy" and a binary (none vs. any toxic) confusion matrix.

*   **`Gemma3_(4B)_finetune.ipynb`**:
    *   Fine-tunes the `unsloth/gemma-3-4b-it` model using Unsloth and LoRA for efficient training.
    *   The model is trained to output comma-separated toxicity labels based on the input comment.
    *   The fine-tuned model adapters are pushed to the Hugging Face Hub at `Subhrato20/gemma-3-toxic-v2`.

*   **`gemma_3_classification.ipynb`**:
    *   The content of this notebook could not be processed. It is presumably intended for inference and evaluation using the fine-tuned Gemma-3 model from `Gemma3_(4B)_finetune.ipynb`.

## Setup & Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/subhrato20/finetuned-slm-vs-llm-with-prompts.git
    cd finetuned-slm-vs-llm-with-prompts
    ```

2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies:**
    A `requirements.txt` file is not provided, but based on the notebooks, key dependencies include:
    ```bash
    pip install pandas scikit-learn iterstrat-ml_stratifiers joblib \
                torch torchvision torchaudio transformers datasets evaluate accelerate \
                openai aiofiles nest_asyncio matplotlib \
                unsloth trl bitsandbytes peft sentencepiece protobuf \
                huggingface_hub hf_transfer
    ```
    *   For `unsloth` on systems other than Colab, you might use `pip install unsloth`. The Colab installation in `Gemma3_(4B)_finetune.ipynb` is specific.
    *   Ensure you have a compatible PyTorch version with CUDA support if you plan to use GPUs for BERT and Gemma fine-tuning.

4.  **API Keys & Tokens:**
    *   For `Gemini_2_5_Pro_Cluster.ipynb`: You will need an API key for the LLM provider (e.g., Google for Gemini or OpenAI if using their client structure). Set it up as required by the `openai` library (e.g., environment variable `OPENAI_API_KEY`).
    *   For `Gemma3_(4B)_finetune.ipynb` (pushing to Hub): A Hugging Face Hub token is required.

5.  **Data:**
    *   Place your training data (`train.parquet` or `train.csv`) and test data (`test_samples.csv`, `test_labels.csv`) in the paths expected by the notebooks (e.g., `data/processed/`, `/content/` for Colab).

## Running the Notebooks

1.  Ensure all prerequisites (data, API keys, installed libraries) are met.
2.  Launch Jupyter Lab or Jupyter Notebook:
    ```bash
    jupyter lab
    # or
    jupyter notebook
    ```
3.  Open and run the desired notebooks.
    *   `baseline_tfidf_ready.ipynb` and `bert_finetune_ready.ipynb` can be run locally if resources permit (BERT fine-tuning benefits significantly from a GPU).
    *   `Gemini_2_5_Pro_Cluster.ipynb` requires an active internet connection and valid API keys.
    *   `Gemma3_(4B)_finetune.ipynb` is set up for a Colab environment with GPU and uses Unsloth for efficient fine-tuning. Adapting it to a local environment might require adjustments.

## Results Summary

The notebooks provide evaluation metrics for their respective models. Here's a high-level summary:

| Model                       | Key Metric(s) Reported                                                                   | Notebook                       |
| :-------------------------- | :--------------------------------------------------------------------------------------- | :----------------------------- |
| **TF-IDF + LogReg**         | Macro F1: 0.787, Micro F1: 0.956, Subset Accuracy: 0.838                                | `baseline_tfidf_ready.ipynb`   |
| **BERT (fine-tuned)**       | Macro F1: 0.856, Micro F1: 0.976, Subset Accuracy: 0.890                                | `bert_finetune_ready.ipynb`    |
| **Gemini 2.5 Pro (Prompted)** | Loose Cluster Accuracy: 0.7475 (single label prediction)                                 | `Gemini_2_5_Pro_Cluster.ipynb` |
| **Gemma-3 4B (Fine-tuned)** | Model adapters pushed to `Subhrato20/gemma-3-toxic-v2`. Evaluation in `gemma_3_classification.ipynb` (content pending). | `Gemma3_(4B)_finetune.ipynb`   |

**Note on Comparability:**
*   The TF-IDF and BERT models are evaluated on a multi-label classification task, predicting a set of applicable labels for each comment.
*   The Gemini 2.5 Pro model is prompted to output a *single most severe* label, and its "loose cluster accuracy" reflects this different task setup.
*   The Gemma-3 4B model is fine-tuned to output comma-separated labels, implying multi-label capability. Detailed evaluation metrics would typically be found in `gemma_3_classification.ipynb`.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Author

*   **Subhrato Som**

## Acknowledgements

*   This project utilizes libraries and tools from the open-source community, including Scikit-learn, PyTorch, Hugging Face Transformers, and Unsloth.
*   The Gemma-3 fine-tuning notebook benefits from the Unsloth library for efficient model training.
